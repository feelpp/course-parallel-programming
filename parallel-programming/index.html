<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Untitled :: Parallel Programming</title>
    <link rel="canonical" href="https://feelpp.github.io/parallel-programming/parallel-programming/index.html">
    <meta name="generator" content="Antora 3.1.10">
    <link rel="stylesheet" href="../_/css/site.css">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
<script>!function(l,p){if(l.protocol!==p&&l.host=="docs.antora.org"){l.protocol=p}else if(/\.gitlab\.io$/.test(l.host)){l.replace(p+"//docs.antora.org"+l.pathname.substr(l.pathname.indexOf("/",1))+l.search+l.hash)}}(location,"https:")</script>

<script src="../_/js/vendor/tabs-block-extension.js"></script>
<script src="../_/js/vendor/tabs-block-behavior.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },

  TeX: {
      Macros: {
      bold: ["{\\bf #1}",1],
      calTh: "{\\mathcal{T}_h}",
      card: ["{\\operatorname{card}(#1)}",1],
      card: ["{\\operatorname{card}(#1)}",1],
      Ck: ["{\\mathcal{C}^{#1}}",1],
      deformt: ["{\\mathbf{\\varepsilon(#1)}}",1],
      diam: "{\\operatorname{diam}}",
      dim: ["{\\operatorname{dim}(#1)}",1],
      disp: ["{\\mathbf{#1}}",1],
      domain: "{\\Omega}",
      ds: "",
      essinf: "{\\operatorname{ess}\\, \\operatorname{inf}}",
      F:"{\\mathcal{F}}",
      geo: "{\\mathrm{geo}}",
      Ich: ["{\\mathcal{I}^{#1}_{c,h}#2}",2],
      Id: "{\\mathcal{I}}",
      Ilag: ["{\\mathcal{I}^{\\mathrm{lag}}_{#1}}",1],
      jump: ["{[\\![ #1 ]\\!]}",1],
      n:"{\\mathbf{n}}",
      Ne: "{N_{\\mathrm{e}}}",
      Next: "{\\mathrm{n}}",
      nf: "{n_f}",
      ngeo: "{n_{\\mathrm{geo}}}",
      Nma: "{N_{\\mathrm{ma}}}",
      NN: "{\\mathbb N}",
      Nno: "{N_{\\mathrm{no}}}",
      Nso: "{N_{\\mathrm{so}}}",
      opdim: "{\\operatorname{dim}}",
      p: "{\\mathrm{p}}",
      P:"{\\mathcal{P}}",
      Pch: ["{P^{#1}_{c,h}}",1],
      Pcho: ["{P^{#1}_{c,h,0}}",1],
      Pk: ["{\\mathcal{P}^{#1}}",1],
      poly: ["{\\mathbb{#1}",1],
      poly: ["{\\mathbb{#1}}",1],
      prect: ["{\\left\\(#1\\right\\)}",1],
      q:"{\\mathbf{q}}",
      Qch: ["{Q^{#1}_{c,h}}",1],
      Qk: ["{\\mathcal{Q}^{#1}}",1],
      R: ["{\\mathbb{R}^{#1}}",1],
      RR: "{\\mathbb R}",
      set: ["{\\left\\{#1\\right\\}}",1],
      stresst: ["{\\mathbf{\\sigma(#1)}}",1],
      T:"{\\mathcal{T}}",
      tr: "{\\operatorname{tr}}",
      v:"{\\mathbf{v}}",
      vertiii: ["\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert",1]
  },
  extensions: ["mhchem.js"] 
  }
});
</script>
<!--<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>-->
<!-- <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML'></script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>-->

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js" integrity="sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq" crossorigin="anonymous"></script>-->
<script>var uiRootPath = '../_'</script>

  </head>
  <body class="article">
<header class="header">
    <nav class="navbar navbar-expand-sm bg-dark navbar-dark navbar-template-project" style="border-top: 4px solid #9E9E9E">
        <div class="navbar-brand">
            <div class="navbar-item feelpp-logo">
                <a href="https://feelpp.github.io/parallel-programming">Parallel Programming</a>
            </div>
            <button class="navbar-burger" data-target="topbar-nav">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>

        <div id="topbar-nav" class="navbar-menu">
            <div class="navbar-end">
                <div class="navbar-item">
                    <a href="https://docs.feelpp.org/">Documentation Reference</a>
                </div>
                <div class="navbar-item has-dropdown is-hoverable download-item">
                    <div class="navbar-item"><a href="https://docs.feelpp.org/user/latest/install/index.html" class="download-btn">Get Feel++</a></div>
                </div>
                <div class="navbar-item">
                    <a class="navbar-brand"  href="https://www.cemosis.fr">
                        <img class="cemosis-logo"  src="../_/img/cemosis-logo.svg" alt="Cemosis logo"/>
                    </a>
                </div>
            </div>
        </div>
    </nav>
</header>
<div class="body">
<a href="#" class="menu-expand-toggle"></a>
<div class="nav-container" data-component="parallel-programming" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html">Main</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="index.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Architectures</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_CPU.html">CPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_GPU.html">GPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_GPGPU.html">GPGPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_TPU.html">TPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_NPU.html">NPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_LPU.html">LPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_DPU.html">DPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_SIMD.html">SIMD Architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="architectures/PPChapter1_AMD_CUDA.html">AMD CUDA Architecture</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">MPI/OpenMP/Hybrid</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="PPChapter2_MPI.html">MPI (Message Passing Interface)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="PPChapter2_MPI_Boost.html">MPI Boost</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="PPChapter2_OpenMP.html">OpenMP (Open Multi-Processing)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="PPChapter2_OpenMP2.html">OpenMP more information</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="PPChapter2_Hybrid.html">Hybrid MPI with OpenMP</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Runtime Systems</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="PPChapter3.html">StarPU</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="PPChapter4.html">Specx</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="kokkos/index.html">Kokkos</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Introduction</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/introduction/why-kokkos.html">Why Kokkos?</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/introduction/installation.html">Installation &amp; Setup</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="kokkos/basic-concepts/index.html">Basic Concepts</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/basic-concepts/views.html">Views</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/basic-concepts/execution-spaces.html">Execution Spaces</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/basic-concepts/memory-spaces.html">Memory Spaces</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/basic-concepts/mirrors.html">Mirrors</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/basic-concepts/memory-access-patterns.html">Memory Access Patterns</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="kokkos/advanced-concepts/index.html">Advanced Concepts</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/advanced-concepts/advanced-reductions.html">Advanced Reductions</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/advanced-concepts/hierarchical-parallelism.html">Hierarchical Parallelism</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/advanced-concepts/mpi.html">MPI</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/advanced-concepts/pgas.html">PGAS</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/advanced-concepts/multidimensional-loops-and-data-structure.html">Multidimensional Loops and Data Structure</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/advanced-concepts/single-instruction-mutliple-data.html">Single Instruction Multiple Data</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/advanced-concepts/asynchronicity-and-streams.html">Asynchronicity and Stream</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="kokkos/diagnostic-tools-algebraic-strategies/index.html">Diagnostic Tools Algebraic Strategies</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/diagnostic-tools-algebraic-strategies/kernels-math-library.html">Kernels Math library</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="kokkos/diagnostic-tools-algebraic-strategies/tools-profiling-tuning-debugging.html">Tools Profing Tuning Debugging</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="kokkos/gaya.html">Compile on Gaya</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Main</span>
    <span class="version"></span>
  </div>
  <ul class="components">
      <li class="component">
        <a class="title" href="../feelpp-antora-ui/index.html">Antora Feel++ UI</a>
      </li>
      <li class="component is-current">
        <a class="title" href="index.html">Main</a>
      </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
  <button class="nav-toggle"></button>
    <a href="index.html" class="home-link is-current"></a>
  <nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Main</a></li>
    <li><a href="index.html">Introduction</a></li>
  </ul>
</nav>

  
    <div class="edit-this-page"><a href="https://github.com/feelpp/course-parallel-programming/edit/feature/kokkos/docs/modules/ROOT/pages/index.adoc">Edit this Page</a></div>
  
  <div class="page-downloads">
  <span class="label">Download as</span>
  <ul class="download-options">
    <li>
      <a onclick="print(this)" href="#" data-toggle="tooltip" data-placement="left" title="Print to PDF"
         class="pdf-download">
        <img class="pdf-file-icon icon" src="../_/img/pdf.svg"/> .pdf
      </a>
    </li>
  </ul>
</div>
</div>

  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="3">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_000"><img src="_images/Begin001.jpg" alt="Begin001"></a>
</div>
</div>
<div class="sidebarblock lead examp">
<div class="content">
<div class="title">INTRODUCTION</div>
<div class="paragraph text-justify">
<p>In many applications today, software must make decisions quickly. And the best way to do so is parallel programming in C / C ++ and Multithreading (multithread programming). Parallel programming is a programming method which allows you to execute several calculations or processes simultaneously. It is used to improve the performance of applications by using multi-core architectures and distributed systems. Parallel programming consists in breaking down a problem into sub-problublicms which can be solved simultaneously by several calculation units. This reduces the overall execution time of a program by effectively using available hardware resources. Parallel machines offer a wonderful opportunity for applications of large calculation requirements. Effective use of these machines, however, requires an in -depth understanding of their operation.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s see more about what computing and programming parallel&#8230;&#8203;</p>
</div>
<div class="paragraph">
<p><strong>1. What is Parallel Computing ?</strong></p>
</div>
<div class="paragraph text-justify">
<p>In the field of computing, the evolution of technologies has led to significant advances in the way we approach complex problems. Among these advances, parallel computing stands out as a revolutionary approach, offering a powerful alternative to traditional serial computing. To fully understand this concept, it is essential to compare these two computing methods and explore their fundamental characteristics. So, let’s first look at serial computing and then dive into the fascinating world of parallel computing</p>
</div>
<div class="paragraph text-justify">
<p><strong>Serial Computing</strong> : Traditionally, software has been developed with a focus on serial computation. In this conventional framework, a problem is decomposed into a discrete series of instructions that are executed sequentially, one after the other, on a single processor. This approach inherently limits the system&#8217;s efficiency, as only one instruction can be processed at any given moment.</p>
</div>
<div class="paragraph text-justify">
<p><strong>Parallel Computing</strong> : In contrast, parallel computing represents a significant advancement in computational methodology. At its core, parallel computing involves the simultaneous utilization of multiple computational resources to address complex problems. In this paradigm, a problem is divided into discrete components that can be solved concurrently. Each component is further segmented into a series of instructions, which are executed simultaneously across different processors. This necessitates the implementation of an overarching control and coordination mechanism to ensure the effective integration of results.</p>
</div>
<div class="paragraph">
<p><strong>2. Overview of the different hardware architectures</strong></p>
</div>
<div class="paragraph text-justify">
<p>In modern computing, various hardware architectures have been developed to address specific computational needs. Each architecture is uniquely designed to optimize performance for particular tasks, ranging from general-purpose processing to specialized operations in graphics, machine learning, and natural language processing. This section explores the key architectures—CPU, GPU, GPGPU, TPU, NPU, and LPU—highlighting their distinct roles and applications in the evolving landscape of technology.</p>
</div>
<div class="paragraph">
<p><strong>2. 1 CPU, GPU, GPGPU Architecture</strong></p>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p><strong>CPU</strong>, <strong>GPU</strong>, and <strong>GPGPU</strong> architectures are all types of computer processing architectures, but they differ in their design and operation.</p>
</li>
</ul>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p><strong>CPU</strong>: A central processor (CPU) is a processing unit that is designed to perform various computing tasks including data processing, mathematical and logical calculations, communication between different components of a computer system, etc. Modern CPUs usually have multiple cores to process multiple tasks simultaneously.</p>
</li>
</ul>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p><strong>GPU</strong>: A graphics processing unit (GPU) is an architecture designed to accelerate the processing of images and graphics. GPUs have thousands of cores that allow them to process millions of pixels simultaneously, making them an ideal choice for video games, 3D modeling, and other graphics-intensive applications.</p>
</li>
</ul>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p><strong>GPGPU</strong>: A General Processing Architecture (GPGPU) is a type of GPU that is designed to be used for purposes other than graphics processing. GPGPUs are used to perform computations of an intensive nature using the hundreds or thousands of cores available on the graphics card. They are particularly effective for parallel computing, machine learning, and other computationally intensive areas.</p>
</li>
</ul>
</div>
<div class="paragraph text-justify">
<p>In conclusion, the main difference between the three architectures CPU, GPU and GPGPU lies in their design and operation. While CPUs are designed for general computer processing, GPUs are designed for specialized graphics processing, and GPGPUs are a modified version of GPUs intended to be used for specialized computer processing other than graphics processing.</p>
</div>
<div class="paragraph">
<p><strong>2.2 TPU, NPU, LPU , DPU Architecture</strong></p>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p><strong>TPU</strong>: A Tensor Processing Unit (TPU) is a specialized hardware processor developed by Google to accelerate machine learning. Unlike traditional CPUs or GPUs, TPUs are specifically designed to handle tensor operations, which account for most of the computations in deep learning models. This makes them incredibly efficient at those tasks and provides an enormous speedup compared to CPUs and GPUs. In this article, we’ll explore what a TPU is, how it works, and why they are so beneficial for machine learning applications.</p>
</li>
</ul>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p><strong>NPU</strong>: A Neural Processing Unit (NPU), is a specialized hardware accelerator designed for executing artificial neural network tasks efficiently and with high throughput. NPUs deliver high performance while minimizing power consumption, making them suitable for mobile devices, edge computing, and other energy-sensitive applications. NPUs use the traditional von Neumann architecture, which separates the memory and the processing units. TPUs use the systolic array architecture, which integrates the memory and the processing units into a single chip. NPUs have a higher peak performance than TPUs, but they also have a higher latency and power consumption. TPUs have a lower peak performance than NPUs, but they also have a lower latency and power consumption.</p>
</li>
</ul>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p><strong>LPU</strong>: Language Processing Units (LPUs) are a relatively new addition, designed specifically for handling the complexities of natural language processing tasks. While CPUs, GPUs, and TPUs play significant roles in the broader field of AI, LPUs offer optimized performance for generative models that deal with text, such as GPT (Generative Pre-trained Transformer). They&#8217;re good at these tasks and might be more efficient than Graphics Processing Units (GPUs). GPUs are still great for things like graphics and AI.The true power of generative AI comes from the interplay and integration of these processing units. CPUs handle the overarching control and coordination, GPUs accelerate the bulk of computational workloads, TPUs offer specialized efficiency for deep learning, and LPUs bring a new level of performance to natural language processing. Together, they form the backbone of generative AI systems, enabling the rapid development and deployment of models that can create highly realistic and complex outputs.</p>
</li>
</ul>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p><strong>DPU</strong>: A Data Processing Unit (DPU) is a specialized processor designed to optimize data-centric workloads in modern computing environments. It combines a multi-core CPU, hardware accelerators, and high-speed networking capabilities into a single system-on-chip (SoC). DPUs are primarily used to offload networking, security, and storage functions from the main CPU, allowing it to focus on running operating systems and applications. This new class of programmable processors is becoming increasingly important in data centers and cloud computing, where they help improve overall system efficiency and performance. DPUs can handle tasks such as packet processing, encryption, and data compression, effectively becoming a third pillar of computing alongside CPUs and GPUs. As data-intensive applications continue to grow, DPUs are expected to play a crucial role in optimizing data movement and processing in large-scale computing environments.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>3. Why Use Parallel Computing ?</strong></p>
</div>
<div class="paragraph text-justify">
<p>Parallel computing is essential for modeling complex real-world phenomena that involve multiple simultaneous events. It utilizes data and task parallelism through shared or distributed memory models. Key benefits include improved performance and scalability, allowing for faster execution times and efficient adaptation to more powerful systems. While parallel computing presents challenges in development and debugging, it remains crucial for solving complex computational problems across various scientific and technological domains. Its ability to handle intricate simulations and process large datasets makes it an indispensable tool in modern computing.</p>
</div>
<div class="paragraph">
<p>Main Reasons for Employing Parallel Programming :</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Time and Cost Efficiency</strong>: Theoretically, allocating additional resources to a task can reduce its completion time, leading to potential cost savings. Furthermore, parallel computers can be constructed using inexpensive commodity components.</p>
</li>
<li>
<p><strong>Solving Large or Complex Problems</strong>: Many problems are so vast or intricate that solving them with a serial program is impractical or impossible, particularly when accounting for limited computer memory.</p>
</li>
<li>
<p><strong>Concurrency</strong>: A single computational resource is limited to executing one task at a time. In contrast, multiple compute resources can perform numerous tasks simultaneously. For example, collaborative networks provide a global platform for individuals from around the world to meet and work together virtually.</p>
</li>
<li>
<p><strong>Utilizing Non-local Resources</strong>: Parallel computing allows for the use of computational resources across wide area networks or even the Internet when local resources are insufficient.</p>
</li>
<li>
<p><strong>Maximizing Hardware Efficiency</strong>: Modern computers, including laptops, are inherently parallel in architecture with multiple processors and cores. Parallel software is specifically designed to exploit this architecture effectively. In many cases, traditional serial programs fail to utilize the full potential of modern computing power.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>4. Kokkos: A Modern Solution for Portable Parallel Programming</strong></p>
</div>
<div class="paragraph text-justify">
<p>Parallel programming has become essential to fully exploit the capabilities of modern hardware architectures. These architectures include different types of specialized processors, each designed for specific tasks:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>CPU (Central Processing Unit)</strong> is the traditional general-purpose processor, capable of performing a wide variety of tasks but with a limited number of cores.</p>
</li>
<li>
<p><strong>GPU (Graphics Processing Unit)</strong> is optimized for massive parallel processing, particularly efficient for graphics computations and certain types of algorithms.</p>
</li>
<li>
<p><strong>TPU (Tensor Processing Unit)</strong> is designed specifically for machine learning and artificial intelligence operations.</p>
</li>
<li>
<p><strong>NPU (Neural Processing Unit)</strong> is similar to the TPU, but usually integrated into mobile devices for local AI tasks.</p>
</li>
</ul>
</div>
<div class="paragraph text-justify">
<p>In this context of hardware diversity, <strong>Kokkos</strong> emerges as a powerful solution for portable parallel programming. <strong>Kokkos</strong> is a C++ library that allows developers to write high-performance parallel code that can run efficiently on various hardware architectures, including multi-core <strong>CPUs</strong> and <strong>GPUs</strong>. This library provides a hardware abstraction that allows expressing parallel algorithms in a way that is independent of the underlying architecture, while automatically optimizing performance for each specific platform. Kokkos thus greatly simplifies the process of developing portable and high-performance parallel applications, by allowing developers to focus on the algorithm rather than on the implementation details specific to each architecture. I therefore invite you to consult the Kokkos section after studying the basics of parallel programming.</p>
</div>
<div class="paragraph">
<p><strong>5. Who Is Using Parallel Computing?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Science and Engineering</strong></p>
<div class="ulist">
<ul>
<li>
<p>Historically, parallel computing has been considered to be "the high end of computing," and has been used to model difficult problems in many areas of science and engineering:</p>
<div class="ulist">
<ul>
<li>
<p>Atmosphere, Earth, Environment</p>
</li>
<li>
<p>Physics - applied, nuclear, particle, condensed matter, high pressure, fusion, photonics</p>
</li>
<li>
<p>Bioscience, Biotechnology, Genetics</p>
</li>
<li>
<p>Chemistry, Molecular Sciences</p>
</li>
<li>
<p>Geology, Seismology</p>
</li>
<li>
<p>Mechanical Engineering - from prosthetics to spacecraft</p>
</li>
<li>
<p>Electrical Engineering, Circuit Design, Microelectronics</p>
</li>
<li>
<p>Computer Science, Mathematics</p>
</li>
<li>
<p>Defense, Weapons</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_007"><img src="_images/simulations01.jpeg" alt="simulations01"></a>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Industrial and Commercial</strong></p>
<div class="ulist">
<ul>
<li>
<p>Today, commercial applications provide an equal or greater driving force in the development of faster computers. These applications require the processing of large amounts of data in sophisticated ways. For example:</p>
<div class="ulist">
<ul>
<li>
<p>"Big Data," databases, data mining</p>
</li>
<li>
<p>Artificial Intelligence (AI)</p>
</li>
<li>
<p>Oil exploration</p>
</li>
<li>
<p>Web search engines, web based business services</p>
</li>
<li>
<p>Medical imaging and diagnosis</p>
</li>
<li>
<p>Pharmaceutical design</p>
</li>
<li>
<p>Financial and economic modeling</p>
</li>
<li>
<p>Management of national and multi-national corporations</p>
</li>
<li>
<p>Advanced graphics and virtual reality, particularly in the entertainment industry</p>
</li>
<li>
<p>Networked video and multi-media technologies</p>
</li>
<li>
<p>Collaborative work environments</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_008"><img src="_images/simulations03.jpeg" alt="simulations03"></a>
</div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title"><strong>DOCUMENTATIONS POWERPOINTS</strong></div>
<div class="imageblock left">
<div class="content">
<img src="_images/PowerPointLogo.png" alt="Img1" width="50" height="50">
</div>
</div>
<div class="paragraph">
<p><a href="_attachments/Session1_ParallelProgramming_Introduction.pdf" class="xref attachment">OVERVIEW</a>,
<a href="_attachments/Session2_ParallelProgramming_MPI.pdf" class="xref attachment">MPI</a>,
<a href="_attachments/Session3_ParallelProgramming_OpenMP.pdf" class="xref attachment">OpenMP</a>,
<a href="_attachments/Session4_ParallelProgramming_Cuda.pdf" class="xref attachment">CUDA</a>,
<a href="_attachments/Session5_ParallelProgramming_HIP.pdf" class="xref attachment">HIP</a>,
<a href="_attachments/Session6_ParallelProgramming_Specx.pdf" class="xref attachment">SPECX</a>,&#8230;&#8203;</p>
</div>
<div class="paragraph">
<p><a href="_attachments/OpenMP-API-Specification-5-2.pdf" class="xref attachment">OpenMP 5.0</a>,
<a href="_attachments/OpenMP-Technical-Report%20-12-Version%206-0.pdf" class="xref attachment">OpenMP 6.0</a>,&#8230;&#8203;</p>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title"><strong>RELEVANT VOCABULARY</strong></div>
<div class="imageblock">
<div class="content">
<img src="_images/CPU1.jpeg" alt="Img2" width="400" height="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Computer Hardware (CPUs, GPUs, and Memory)</strong></p>
<div class="ulist">
<ul>
<li>
<p><strong>CPU-chip</strong> – CPU stands for Central Processing Unit. This is the computer&#8217;s main processing unit; you can think of it as the 'brain' of the computer. This is the piece of hardware that performs calculations, moves data around, has access to the memory, etc. In systems such as Princeton&#8217;s High Performance Computing clusters, CPU-chips are made of multiple CPU-cores.</p>
</li>
<li>
<p><strong>CPU-core</strong> – A microprocessing unit on a CPU-chip. Each CPU-core can execute an independent set of instructions from the computer.</p>
</li>
<li>
<p><strong>GPU</strong> –GPU stands for the Graphics Processing Unit. Originally intended to process graphics, in the context of parallel programming this unit can do a large number of simple arithmetic computations.</p>
</li>
<li>
<p><strong>MEMORY</strong> – In this guide memory refers to Random-Access Memory, or RAM. The RAM unit stores the data that the CPU is actively working on.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/ParallelProgramming1.jpeg" alt="Img3" width="400" height="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Additional Parallelism Terminology</strong></p>
<div class="ulist">
<ul>
<li>
<p>An understanding of threads and processes is also useful when discussing parallel programming concepts.</p>
</li>
<li>
<p>If you consider the code you need to run as one big job, to run that code in parallel you&#8217;ll want to divide that one big job into several, smaller tasks that can be run at the same time. This is the general idea behind parallel programming.</p>
</li>
<li>
<p>When tasks are run as threads, the tasks all share direct access to a common region of memory. The mulitple threads are considered to belong to one process.</p>
</li>
<li>
<p>When tasks run as distinct processes, each process gets its own individual region of memory–even if run on the same computer.</p>
</li>
<li>
<p>To put it even more simply, processes have their own memory, while threads belong to a process and share memory with all of the other threads belonging to that process.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Coding Practice {c,c++,cu}</div>
<div class="ulist">
<ul>
<li>
<p><a href="MPI_Coding.html" class="xref page">MPI Coding</a></p>
</li>
<li>
<p><a href="OpenMP_Coding.html" class="xref page">OpenMP Coding</a></p>
</li>
<li>
<p><a href="CUDA_Coding.html" class="xref page">CUDA Coding</a></p>
</li>
<li>
<p><a href="HIP_Coding.html" class="xref page">HIP Coding</a></p>
</li>
<li>
<p><a href="Hybrid_Coding.html" class="xref page">Hybrid Coding</a></p>
</li>
<li>
<p><a href="SPECX_Coding.html" class="xref page">SPECX Coding</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Case Studies</div>
<div class="ulist">
<ul>
<li>
<p><a href="HEAT_Coding.html" class="xref page">Case Study Heat Coding</a></p>
</li>
</ul>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer" style="border-top: 2px solid #e9e9e9; background-color: #fafafa; padding-bottom: 2em; padding-top: 2em;">
    <div class="container" style="display: flex; flex-direction: column; align-items: center; gap: 0.5em;">
        <div>
            <a href="https://www.cemosis.fr">
                <img src="../_/img/cemosis-logo.svg" alt="Cemosis logo" height="50">
            </a>
        </div>
        <span style="font-size: 0.8rem; color: #9e9e9e">© 2025 <a href="https://www.cemosis.fr" style="text-decoration: underline;">Cemosis</a>, Université de Strasbourg</span>
    </div>
</footer>
<script id="site-script" src="../_/js/site.js" data-ui-root-path="../_"></script>


<script async src="../_/js/vendor/fontawesome-icon-defs.js"></script>
<script async src="../_/js/vendor/fontawesome.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>


<script type="text/javascript">
function toggleFullScreen() {
   var doc = window.document;
   var docEl = doc.documentElement;

   var requestFullScreen = docEl.requestFullscreen || docEl.mozRequestFullScreen || docEl.webkitRequestFullScreen || docEl.msRequestFullscreen;
   var cancelFullScreen = doc.exitFullscreen || doc.mozCancelFullScreen || doc.webkitExitFullscreen || doc.msExitFullscreen;

   if(!doc.fullscreenElement && !doc.mozFullScreenElement && !doc.webkitFullscreenElement && !doc.msFullscreenElement) {
       requestFullScreen.call(docEl);
   }
   else {
       cancelFullScreen.call(doc);
   }
}
</script>
  </body>
</html>
