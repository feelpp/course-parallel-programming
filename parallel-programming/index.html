<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Untitled :: Parallel Programming</title>
    <link rel="canonical" href="https://feelpp.github.io/parallel-programming/parallel-programming/index.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../_/css/site.css">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
<script>!function(l,p){if(l.protocol!==p&&l.host=="docs.antora.org"){l.protocol=p}else if(/\.gitlab\.io$/.test(l.host)){l.replace(p+"//docs.antora.org"+l.pathname.substr(l.pathname.indexOf("/",1))+l.search+l.hash)}}(location,"https:")</script>

<script src="../_/js/vendor/tabs-block-extension.js"></script>
<script src="../_/js/vendor/tabs-block-behavior.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },

  TeX: {
      Macros: {
      bold: ["{\\bf #1}",1],
      calTh: "{\\mathcal{T}_h}",
      card: ["{\\operatorname{card}(#1)}",1],
      card: ["{\\operatorname{card}(#1)}",1],
      Ck: ["{\\mathcal{C}^{#1}}",1],
      deformt: ["{\\mathbf{\\varepsilon(#1)}}",1],
      diam: "{\\operatorname{diam}}",
      dim: ["{\\operatorname{dim}(#1)}",1],
      disp: ["{\\mathbf{#1}}",1],
      domain: "{\\Omega}",
      ds: "",
      essinf: "{\\operatorname{ess}\\, \\operatorname{inf}}",
      F:"{\\mathcal{F}}",
      geo: "{\\mathrm{geo}}",
      Ich: ["{\\mathcal{I}^{#1}_{c,h}#2}",2],
      Id: "{\\mathcal{I}}",
      Ilag: ["{\\mathcal{I}^{\\mathrm{lag}}_{#1}}",1],
      jump: ["{[\\![ #1 ]\\!]}",1],
      n:"{\\mathbf{n}}",
      Ne: "{N_{\\mathrm{e}}}",
      Next: "{\\mathrm{n}}",
      nf: "{n_f}",
      ngeo: "{n_{\\mathrm{geo}}}",
      Nma: "{N_{\\mathrm{ma}}}",
      NN: "{\\mathbb N}",
      Nno: "{N_{\\mathrm{no}}}",
      Nso: "{N_{\\mathrm{so}}}",
      opdim: "{\\operatorname{dim}}",
      p: "{\\mathrm{p}}",
      P:"{\\mathcal{P}}",
      Pch: ["{P^{#1}_{c,h}}",1],
      Pcho: ["{P^{#1}_{c,h,0}}",1],
      Pk: ["{\\mathcal{P}^{#1}}",1],
      poly: ["{\\mathbb{#1}",1],
      poly: ["{\\mathbb{#1}}",1],
      prect: ["{\\left\\(#1\\right\\)}",1],
      q:"{\\mathbf{q}}",
      Qch: ["{Q^{#1}_{c,h}}",1],
      Qk: ["{\\mathcal{Q}^{#1}}",1],
      R: ["{\\mathbb{R}^{#1}}",1],
      RR: "{\\mathbb R}",
      set: ["{\\left\\{#1\\right\\}}",1],
      stresst: ["{\\mathbf{\\sigma(#1)}}",1],
      T:"{\\mathcal{T}}",
      tr: "{\\operatorname{tr}}",
      v:"{\\mathbf{v}}",
      vertiii: ["\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert",1]
  },
  extensions: ["mhchem.js"] 
  }
});
</script>
<!--<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>-->
<!-- <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML'></script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>-->

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js" integrity="sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq" crossorigin="anonymous"></script>-->
<script>var uiRootPath = '../_'</script>

  </head>
  <body class="article">
<header class="header">
    <nav class="navbar navbar-expand-sm bg-dark navbar-dark navbar-template-project" style="border-top: 4px solid #9E9E9E">
        <div class="navbar-brand">
            <div class="navbar-item feelpp-logo">
                <a href="https://feelpp.github.io/parallel-programming">Parallel Programming</a>
            </div>
            <button class="navbar-burger" data-target="topbar-nav">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>

        <div id="topbar-nav" class="navbar-menu">
            <div class="navbar-end">
                <div class="navbar-item">
                    <a href="https://docs.feelpp.org/">Documentation Reference</a>
                </div>
                <div class="navbar-item has-dropdown is-hoverable download-item">
                    <div class="navbar-item"><a href="https://docs.feelpp.org/user/latest/install/index.html" class="download-btn">Get Feel++</a></div>
                </div>
                <div class="navbar-item">
                    <a class="navbar-brand"  href="https://www.cemosis.fr">
                        <img class="cemosis-logo"  src="../_/img/cemosis-logo.svg" alt="Cemosis logo"/>
                    </a>
                </div>
            </div>
        </div>
    </nav>
</header>
<div class="body">
<a href="#" class="menu-expand-toggle"></a>
<div class="nav-container" data-component="parallel-programming" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html">Main</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="index.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_CPU.html">CPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_GPU.html">GPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_GPGPU.html">GPGPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_TPU.html">TPU Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter1_SIMD.html">SIMD Architecture</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_MPI.html">MPI (Message Passing Interface)</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_OpenMP.html">OpenMP (Open Multi-Processing)</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter2_Hybrid.html">Hybrid MPI with OpenMP</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter3.html">StarPU</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="PPChapter4.html">Specx</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Main</span>
    <span class="version"></span>
  </div>
  <ul class="components">
      <li class="component">
        <a class="title" href="../feelpp-antora-ui/index.html">Antora Feel++ UI</a>
      </li>
      <li class="component is-current">
        <a class="title" href="index.html">Main</a>
      </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
  <button class="nav-toggle"></button>
    <a href="index.html" class="home-link is-current"></a>
  <nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Main</a></li>
    <li><a href="index.html">Introduction</a></li>
  </ul>
</nav>

  
    <div class="edit-this-page"><a href="https://github.com/feelpp/parallel-programming/edit/lem/docs/modules/ROOT/pages/index.adoc">Edit this Page</a></div>
  
  <div class="page-downloads">
  <span class="label">Download as</span>
  <ul class="download-options">
    <li>
      <a onclick="print(this)" href="#" data-toggle="tooltip" data-placement="left" title="Print to PDF"
         class="pdf-download">
        <img class="pdf-file-icon icon" src="../_/img/pdf.svg"/> .pdf
      </a>
    </li>
  </ul>
</div>
</div>

  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_000"><img src="_images/Begin001.jpg" alt="Begin001"></a>
</div>
</div>
<div class="sidebarblock lead examp">
<div class="content">
<div class="title">INTRODUCTION</div>
<div class="paragraph">
<p>In many applications today, software needs to make decisions quickly. And the best way to do that is through parallel programming in C/C++ and multithreading (multithreaded programming). Parallel programming is a broad concept. It can describe many types of processes running on the same machine or on different machines. Parallel machines provide a wonderful opportunity for applications with large computational requirements. Effective use of these machines, though, requires a keen understanding of how they work.</p>
</div>
<div class="paragraph">
<p><strong>What Is Parallel Computing?</strong></p>
</div>
<div class="paragraph">
<p><strong>Serial Computing</strong></p>
</div>
<div class="paragraph">
<p>Traditionally, software has been written for serial computation:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A problem is broken into a discrete series of instructions</p>
</li>
<li>
<p>Instructions are executed sequentially one after another</p>
</li>
<li>
<p>Executed on a single processor</p>
</li>
<li>
<p>Only one instruction may execute at any moment in time</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_001"><img src="_images/serialProblem.gif" alt="serialProblem"></a>
</div>
</div>
<div class="paragraph">
<p><strong>Parallel Computing</strong></p>
</div>
<div class="paragraph">
<p>In the simplest sense, parallel computing is the simultaneous use of multiple compute resources to solve a computational problem:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A problem is broken into discrete parts that can be solved concurrently</p>
<div class="ulist">
<ul>
<li>
<p>Each part is further broken down to a series of instructions</p>
</li>
<li>
<p>Instructions from each part execute simultaneously on different processors</p>
</li>
<li>
<p>An overall control/coordination mechanism is employed</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_002"><img src="_images/parallelProblem.gif" alt="parallelProblem"></a>
</div>
</div>
<div class="paragraph">
<p>For example</p>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_003"><img src="_images/parallelProblem2.gif" alt="parallelProblem2"></a>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>The computational problem should be able to:</p>
<div class="ulist">
<ul>
<li>
<p>Be broken apart into discrete pieces of work that can be solved simultaneously;</p>
</li>
<li>
<p>Execute multiple program instructions at any moment in time;</p>
</li>
<li>
<p>Be solved in less time with multiple compute resources than with a single compute resource.</p>
</li>
</ul>
</div>
</li>
<li>
<p>The compute resources are typically:</p>
<div class="ulist">
<ul>
<li>
<p>A single computer with multiple processors/cores</p>
</li>
<li>
<p>An arbitrary number of such computers connected by a network</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Parallel Computers</strong></p>
</div>
<div class="paragraph">
<p><strong>Virtually all stand-alone computers today are parallel from a hardware perspective:
<strong> Multiple functional units (L1 cache, L2 cache, branch, prefetch, decode, floating-point, graphics processing (GPU), integer, etc.)
</strong> Multiple execution units/cores
*</strong> Multiple hardware threads</p>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_004"><img src="_images/bgqComputeChip.jpeg" alt="bgqComputeChip"></a>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Networks connect multiple stand-alone computers (nodes) to make larger parallel computer clusters.</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_005"><img src="_images/nodesNetwork.gif" alt="nodesNetwork"></a>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>For example, the schematic below shows a typical LLNL parallel computer cluster:</p>
<div class="ulist">
<ul>
<li>
<p>Each compute node is a multi-processor parallel computer in itself</p>
</li>
<li>
<p>Multiple compute nodes are networked together with an Infiniband network</p>
</li>
<li>
<p>Special purpose nodes, also multi-processor, are used for other purposes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_006"><img src="_images/parallelComputer1.gif" alt="parallelComputer1"></a>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>The majority of the world&#8217;s large parallel computers (supercomputers) are clusters of hardware produced by a handful of (mostly) well known vendors.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>CPU, GPU, GPGPU Architecture</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>CPU, GPU, and GPGPU architectures are all types of computer processing
architectures, but they differ in their design and operation.</p>
</li>
<li>
<p>CPU: A central processor (CPU) is a processing unit that is designed to
perform various computing tasks including data processing, mathematical
and logical calculations, communication between different components of
a computer system, etc. Modern CPUs usually have multiple cores to
process multiple tasks simultaneously.</p>
</li>
<li>
<p>GPU: A graphics processing unit (GPU) is an architecture designed to
accelerate the processing of images and graphics. GPUs have thousands of
cores that allow them to process millions of pixels simultaneously,
making them an ideal choice for video games, 3D modeling, and other
graphics-intensive applications.</p>
</li>
<li>
<p>GPGPU: A General Processing Architecture (GPGPU) is a type of GPU that
is designed to be used for purposes other than graphics processing.
GPGPUs are used to perform computations of an intensive nature using the
hundreds or thousands of cores available on the graphics card. They are
particularly effective for parallel computing, machine learning, and
other computationally intensive areas.</p>
</li>
<li>
<p>In conclusion, the main difference between the three architectures CPU,
GPU and GPGPU lies in their design and operation. While CPUs are
designed for general computer processing, GPUs are designed for
specialized graphics processing, and GPGPUs are a modified version of
GPUs intended to be used for specialized computer processing other than
graphics processing.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Why Use Parallel Computing?</strong></p>
</div>
<div class="paragraph">
<p>The Real World Is Massively Complex</p>
</div>
<div class="ulist">
<ul>
<li>
<p>In the natural world, many complex, interrelated events are happening at the same time, yet within a temporal sequence.</p>
</li>
<li>
<p>Compared to serial computing, parallel computing is much better suited for modeling, simulating and understanding complex, real world phenomena.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Main Reasons for Using Parallel Programming</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Save time and or money</p>
<div class="ulist">
<ul>
<li>
<p>In theory, throwing more resources at a task will shorten its time to completion, with potential cost savings.</p>
</li>
<li>
<p>Parallel computers can be built from cheap, commodity components</p>
</li>
</ul>
</div>
</li>
<li>
<p>Solver large/ More complex problems</p>
<div class="ulist">
<ul>
<li>
<p>Many problems are so large and/or complex that it is impractical or impossible to solve them using a serial program, especially given limited computer memory.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Provide concurency</p>
<div class="ulist">
<ul>
<li>
<p>A single compute resource can only do one thing at a time. Multiple compute resources can do many things simultaneously.</p>
</li>
<li>
<p>Example: Collaborative Networks provide a global venue where people from around the world can meet and conduct work "virtually."</p>
</li>
</ul>
</div>
</li>
<li>
<p>Take advantage of non-local resources</p>
<div class="ulist">
<ul>
<li>
<p>Using compute resources on a wide area network, or even the Internet when local compute resources are scarce or insufficient.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Make better use of underlying parallel hardware</p>
<div class="ulist">
<ul>
<li>
<p>Modern computers, even laptops, are parallel in architecture with multiple processors/cores.</p>
</li>
<li>
<p>Parallel software is specifically intended for parallel hardware with multiple cores, threads, etc.</p>
</li>
<li>
<p>In most cases, serial programs run on modern computers "waste" potential computing power.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Who Is Using Parallel Computing?</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Science and Engineering</strong></p>
<div class="ulist">
<ul>
<li>
<p>Historically, parallel computing has been considered to be "the high end of computing," and has been used to model difficult problems in many areas of science and engineering:</p>
<div class="ulist">
<ul>
<li>
<p>Atmosphere, Earth, Environment</p>
</li>
<li>
<p>Physics - applied, nuclear, particle, condensed matter, high pressure, fusion, photonics</p>
</li>
<li>
<p>Bioscience, Biotechnology, Genetics</p>
</li>
<li>
<p>Chemistry, Molecular Sciences</p>
</li>
<li>
<p>Geology, Seismology</p>
</li>
<li>
<p>Mechanical Engineering - from prosthetics to spacecraft</p>
</li>
<li>
<p>Electrical Engineering, Circuit Design, Microelectronics</p>
</li>
<li>
<p>Computer Science, Mathematics</p>
</li>
<li>
<p>Defense, Weapons</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_007"><img src="_images/simulations01.jpeg" alt="simulations01"></a>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Industrial and Commercial</strong></p>
<div class="ulist">
<ul>
<li>
<p>Today, commercial applications provide an equal or greater driving force in the development of faster computers. These applications require the processing of large amounts of data in sophisticated ways. For example:</p>
<div class="ulist">
<ul>
<li>
<p>"Big Data," databases, data mining</p>
</li>
<li>
<p>Artificial Intelligence (AI)</p>
</li>
<li>
<p>Oil exploration</p>
</li>
<li>
<p>Web search engines, web based business services</p>
</li>
<li>
<p>Medical imaging and diagnosis</p>
</li>
<li>
<p>Pharmaceutical design</p>
</li>
<li>
<p>Financial and economic modeling</p>
</li>
<li>
<p>Management of national and multi-national corporations</p>
</li>
<li>
<p>Advanced graphics and virtual reality, particularly in the entertainment industry</p>
</li>
<li>
<p>Networked video and multi-media technologies</p>
</li>
<li>
<p>Collaborative work environments</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<a class="image" href="#fragment_000_008"><img src="_images/simulations03.jpeg" alt="simulations03"></a>
</div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title"><strong>DOCUMENTATIONS POWERPOINTS</strong></div>
<div class="imageblock left">
<div class="content">
<img src="_images/PowerPointLogo.png" alt="Img1" width="50" height="50">
</div>
</div>
<div class="paragraph">
<p><a href="_attachments/Session1_ParallelProgramming_Introduction.pdf" class="xref attachment">OVERVIEW</a>,
<a href="_attachments/Session2_ParallelProgramming_MPI.pdf" class="xref attachment">MPI</a>,
<a href="_attachments/Session3_ParallelProgramming_OpenMP.pdf" class="xref attachment">OpenMP</a>,
<a href="_attachments/Session4_ParallelProgramming_Cuda.pdf" class="xref attachment">CUDA</a>,
<a href="_attachments/Session5_ParallelProgramming_HIP.pdf" class="xref attachment">HIP</a>,
<a href="_attachments/Session6_ParallelProgramming_Specx.pdf" class="xref attachment">HIP</a>,&#8230;&#8203;</p>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title"><strong>RELEVANT VOCABULARY</strong></div>
<div class="imageblock">
<div class="content">
<img src="_images/CPU1.jpeg" alt="Img2">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Computer Hardware (CPUs, GPUs, and Memory)</strong></p>
<div class="ulist">
<ul>
<li>
<p><strong>CPU-chip</strong> – CPU stands for Central Processing Unit. This is the computer&#8217;s main processing unit; you can think of it as the 'brain' of the computer. This is the piece of hardware that performs calculations, moves data around, has access to the memory, etc. In systems such as Princeton&#8217;s High Performance Computing clusters, CPU-chips are made of multiple CPU-cores.</p>
</li>
<li>
<p><strong>CPU-core</strong> – A microprocessing unit on a CPU-chip. Each CPU-core can execute an independent set of instructions from the computer.</p>
</li>
<li>
<p><strong>GPU</strong> –GPU stands for the Graphics Processing Unit. Originally intended to process graphics, in the context of parallel programming this unit can do a large number of simple arithmetic computations.</p>
</li>
<li>
<p><strong>MEMORY</strong> – In this guide memory refers to Random-Access Memory, or RAM. The RAM unit stores the data that the CPU is actively working on.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/ParallelProgramming1.jpeg" alt="Img3">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Additional Parallelism Terminology</strong></p>
<div class="ulist">
<ul>
<li>
<p>An understanding of threads and processes is also useful when discussing parallel programming concepts.</p>
</li>
<li>
<p>If you consider the code you need to run as one big job, to run that code in parallel you&#8217;ll want to divide that one big job into several, smaller tasks that can be run at the same time. This is the general idea behind parallel programming.</p>
</li>
<li>
<p>When tasks are run as threads, the tasks all share direct access to a common region of memory. The mulitple threads are considered to belong to one process.</p>
</li>
<li>
<p>When tasks run as distinct processes, each process gets its own individual region of memory–even if run on the same computer.</p>
</li>
<li>
<p>To put it even more simply, processes have their own memory, while threads belong to a process and share memory with all of the other threads belonging to that process.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock examp">
<div class="content">
<div class="title">Coding {c,c++,cu}</div>

</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer" style="border-top: 2px solid #e9e9e9; background-color: #fafafa; padding-bottom: 2em; padding-top: 2em;">
    <div class="container" style="display: flex; flex-direction: column; align-items: center; gap: 0.5em;">
        <div>
            <a href="https://www.cemosis.fr">
                <img src="../_/img/cemosis-logo.svg" alt="Cemosis logo" height="50">
            </a>
        </div>
        <span style="font-size: 0.8rem; color: #9e9e9e">© 2023 <a href="https://www.cemosis.fr" style="text-decoration: underline;">Cemosis</a>, Université de Strasbourg</span>
    </div>
</footer>
<script id="site-script" src="../_/js/site.js" data-ui-root-path="../_"></script>


<script async src="../_/js/vendor/fontawesome-icon-defs.js"></script>
<script async src="../_/js/vendor/fontawesome.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>


<script type="text/javascript">
function toggleFullScreen() {
   var doc = window.document;
   var docEl = doc.documentElement;

   var requestFullScreen = docEl.requestFullscreen || docEl.mozRequestFullScreen || docEl.webkitRequestFullScreen || docEl.msRequestFullscreen;
   var cancelFullScreen = doc.exitFullscreen || doc.mozCancelFullScreen || doc.webkitExitFullscreen || doc.msExitFullscreen;

   if(!doc.fullscreenElement && !doc.mozFullScreenElement && !doc.webkitFullscreenElement && !doc.msFullscreenElement) {
       requestFullScreen.call(docEl);
   }
   else {
       cancelFullScreen.call(doc);
   }
}
</script>
  </body>
</html>
